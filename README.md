# GFRCKD
The paper proposes an efficient distillation method named Generated Feature with Recycled Class-Token Knowledge Distillation (GFRCKD). To address student feature biases, we apply convolutional generative features that help mitigate these biases, enabling the student model to actively learn from the teacher model by minimizing distance loss. 
